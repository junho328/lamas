algorithm_name: APPO
normalization_mode: sum
agent_iteration_interval: 0
experiment_name: qwen_coding_duo
seed: 42
cuda: false
cuda_deterministic: true
n_training_threads: 1
n_rollout_threads: 16
n_eval_rollout_threads: 1
num_env_steps: 1000000
horizon: 1
env_name: CODING
dataset_name: bigcodebench
train_dataset_path: data/bigcodebench_instruct_train_marft.json
test_dataset_path: data/bigcodebench_instruct_test_marft.json
flag: train
model_name_or_path: Qwen/Qwen2.5-Coder-1.5B-Instruct
load_path: null
max_new_tokens: 512
n_agents: 2
profile_path: scripts/profiles/qwen_coding_duo.json
context_window: 2048
episode_length: 200
warmup_steps: 0
hidden_size: 64
use_orthogonal: false
lr: 5.0e-07
critic_lr: 0.0005
opti_eps: 1.0e-05
weight_decay: 0.0
gradient_cp_steps: 1
ppo_epoch: 1
use_clipped_value_loss: false
clip_param: 0.2
num_mini_batch: 4
entropy_coef: 0.01
value_loss_coef: 1.0
use_max_grad_norm: false
max_grad_norm: 0.5
use_gae: false
gamma: 0.99
gae_lambda: 0.95
use_proper_time_limits: true
use_huber_loss: false
use_value_active_masks: false
use_policy_active_masks: false
huber_delta: 10.0
kl_threshold: 0.001
use_linear_lr_decay: true
save_interval: 50
log_interval: 1
use_eval: true
eval_interval: 10
eval_episodes: 10
use_wandb: true
wandb_project: qwen-coding-marft
wandb_entity: lamas-aipr
wandb_run_name: qwen-coder-duo-qwen2.5-1.5b
reward_type: binary
use_vllm: true
vllm_gpu_memory_utilization: 0.8
vllm_temperature: 0.8
vllm_top_p: 0.95
base_model: Qwen2.5-Coder-1.5B-Instruct
