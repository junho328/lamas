# Qwen/Qwen2.5-Coder-1.5B-Instruct QLoRA 훈련 설정

# 기본 설정
algorithm_name: APPO
experiment_name: qwen_coding_duo
seed: 42
cuda: true
n_training_threads: 1
n_rollout_threads: 8
n_eval_rollout_threads: 1
num_env_steps: 1000000
horizon: 1

# 환경 설정
env_name: CODING
dataset_name: bigcodebench_instruct
train_dataset_path: data/bigcodebench_instruct_marft.json
test_dataset_path: data/bigcodebench_instruct_marft.json
flag: train

# 모델 설정
model_name_or_path: Qwen/Qwen2.5-Coder-1.5B-Instruct
max_new_tokens: 512
n_agents: 2
profile_path: scripts/profiles/qwen_coding_duo.json
context_window: 2048

# QLoRA 설정
load_in_4bit: true
bf16: true

# 훈련 설정
episode_length: 200
warmup_steps: 0
hidden_size: 64
use_orthogonal: true

# 옵티마이저 설정
lr: 5e-7
critic_lr: 5e-4
opti_eps: 1e-5
weight_decay: 0

# PPO 설정
gradient_cp_steps: 1
ppo_epoch: 5
use_clipped_value_loss: true
clip_param: 0.2
num_mini_batch: 4
entropy_coef: 0.01
value_loss_coef: 1
use_max_grad_norm: true
max_grad_norm: 0.5
use_gae: true
gamma: 0.99
gae_lambda: 0.95
use_proper_time_limits: false
use_huber_loss: true
use_value_active_masks: true
use_policy_active_masks: true
huber_delta: 10.0
kl_threshold: 1e-3

# 학습률 스케줄링
use_linear_lr_decay: true

# 저장 및 로깅
save_interval: 50
log_interval: 1

# 평가 설정
use_eval: true
eval_interval: 10
eval_episodes: 10

# Wandb 설정
use_wandb: true
wandb_project: qwen-coding-marft
wandb_entity: lamas-aipr
wandb_run_name: qwen-coder-duo-qwen2.5-1.5b

# 보상 설정
reward_type: binary
